{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 - Competitive Assignment\n",
    "An explanation this assignment could be found in the .pdf explanation document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external modules (packages). <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for reading and writing (input & output) files:\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add whatever imports you need\n",
    "# YOUR CODE HERE\n",
    "import numpy as np\n",
    "import hebrew_tokenizer as ht\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = '.' + os.sep + 'input' + os.sep + 'annotated_corpus_for_train.xlsx'\n",
    "test_filename  = '.' + os.sep + 'input' + os.sep + 'corpus_for_test.xlsx'\n",
    "df_train = pd.read_excel(train_filename, 'corpus', index_col=None, na_values=['NA'])\n",
    "df_test  = pd.read_excel(test_filename,  'corpus', index_col=None, na_values=['NA'])\n",
    "\n",
    "#i add some more words that seems to appear a lot \n",
    "\n",
    "stop_word=open(\"stop_word_list_heb_example.txt\", \"r\",encoding=\"utf8\")\n",
    "stop_word_temp=stop_word.read()\n",
    "\n",
    "# turning the stop word text to a list to stop word's\n",
    "\n",
    "stop_word_toList=stop_word_temp.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>בוקר אחד קמתי סהרורי יצאתי מהמיטה קצת מטושטש ,...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>לחבר שלי היה יום הולדת וחיפשנו מה אפשר לעשות ל...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>השנה האחרונה הייתה שנת קורונה, שנה לא פשוטה בק...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>לפני כחצי שנה עברתי לגור בצפון עם בת זוגתי, עב...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>יום חמישי רגיל, תמיד מתחיל לעבור טיפה מאוחר יו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>בשנה האחרונה חוויתי את מגפת הקורונה שהכריח את ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>בסמסטר קודם אני וכמה חברים ללימודים קבענו להיפ...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>בשנה האחרונה למרות שלא היו יותר מידיי דברים לע...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story gender\n",
       "0  בוקר אחד קמתי סהרורי יצאתי מהמיטה קצת מטושטש ,...      m\n",
       "1  לחבר שלי היה יום הולדת וחיפשנו מה אפשר לעשות ל...      m\n",
       "2  השנה האחרונה הייתה שנת קורונה, שנה לא פשוטה בק...      m\n",
       "3  לפני כחצי שנה עברתי לגור בצפון עם בת זוגתי, עב...      m\n",
       "4  יום חמישי רגיל, תמיד מתחיל לעבור טיפה מאוחר יו...      m\n",
       "5  בשנה האחרונה חוויתי את מגפת הקורונה שהכריח את ...      m\n",
       "6  בסמסטר קודם אני וכמה חברים ללימודים קבענו להיפ...      m\n",
       "7  בשנה האחרונה למרות שלא היו יותר מידיי דברים לע...      f"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>כחלק ממסגרת ההתנדבות שלי במגלה אני הולך לפעמיי...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>לפני שנה החלטתי שאני רוצה להיות טייס, התחלתי ל...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>בתקופת הקורונה של תחילת החיסונים נגד קורונה, א...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_example_id                                              story\n",
       "0                0  כחלק ממסגרת ההתנדבות שלי במגלה אני הולך לפעמיי...\n",
       "1                1  לפני שנה החלטתי שאני רוצה להיות טייס, התחלתי ל...\n",
       "2                2  בתקופת הקורונה של תחילת החיסונים נגד קורונה, א..."
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation:\n",
    "Write your code solution in the following code-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning 'm' and 'f' to '1' and '0'\n",
    "train_target = pd.Series(df_train['gender']).replace('m',1).replace('f',0)\n",
    "train_data =   pd.Series(df_train['story'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# i was thinking about word that imply that is a female wrote this text and change it to 'נקבה'.\n",
    "def my_tokenizer(hebrew_text):\n",
    "    tokens = ht.tokenize(hebrew_text) \n",
    "    list_strings=[]\n",
    "    for grp, token, token_num, (start_index, end_index) in tokens:\n",
    "        if token==\"אוכלת\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"יושבת\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"לוקחת\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"הולכת\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"לקחה\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"כתבה\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"חשבה\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"ישנה\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"אכלה\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"לוקחת\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"קופצת\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"ישנה\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"צרחה\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"אוהבת\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"לובשת\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"יודעת\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"בן זוגי\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"התלבשה\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"נסעה\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"חשבה\":\n",
    "            token=\"נקבה\"\n",
    "        if token==\"בעלי\":\n",
    "            token=\"נקבה\"\n",
    "        if token ==\"אהובי\":\n",
    "            token =\"נקבה\"\n",
    "        if token ==\"ארוסי\":\n",
    "            token =\"נקבה\"\n",
    "        if token ==\"חושבת\":\n",
    "            token =\"נקבה\"\n",
    "        if token ==\"מתלבשת\":\n",
    "            token =\"נקבה\"\n",
    "        if token ==\"יוצאת\":\n",
    "            token =\"נקבה\"\n",
    "        list_strings.append(token)\n",
    "    return  list_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yagel Abbou\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['נקבה'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# my approuch was to use enasmble method which combine a severel base estimators.\n",
    "# the Gradient boosting Classifire built sequentially and one tries to reduce the bias of the combined estimator.\n",
    "# The motivation is to combine several weak models to produce a powerful ensemble.\n",
    "# selecting Gradient boosting Classifire was after playing with KNN, desicion tree, naive bayas and others with various parameters.\n",
    "\n",
    "text_clf_GBC = Pipeline([\n",
    "    ('vect', CountVectorizer(stop_words=heb_stop_word_List,max_features=20000,tokenizer=my_tokenizer,ngram_range=(1,4))),\n",
    "    ('norm', preprocessing.Normalizer(norm='l2')),\n",
    "    ('clf', GradientBoostingClassifier(n_estimators=80, learning_rate=1.0,max_depth=1, random_state=0)),\n",
    "])\n",
    "\n",
    "text_clf_GBC.fit(train_data, train_target)\n",
    "predicted_GBC = text_clf_GBC.predict(df_test['story'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many code cells as you need\n",
    "# YOUR CODE HERE\n",
    "\n",
    "#returning every '1' and '0' to 'm' and 'f'\n",
    "test_target_gender = pd.Series(predicted_ADABC).replace(1,'m').replace(0,'f')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv\n",
    "After you're done save your output to the 'classification_results.csv' csv file.<br/>\n",
    "We assume that the dataframe with your results contain the following columns:\n",
    "* column 1 (left column): 'test_example_id'  - the same id associated to each of the test stories to be predicted.\n",
    "* column 2 (right column): 'predicted_category' - the predicted gender value for each of the associated story. \n",
    "\n",
    "Assuming your predicted values are in the `df_predicted` dataframe, you should save you're results as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(test_target_gender.size)\n",
    "test_data_csv = pd.DataFrame(columns=('test_example_id','predicted_category'))\n",
    "test_data_csv['test_example_id']=index\n",
    "test_data_csv['predicted_category']=test_target_gender\n",
    "test_data_csv.to_csv(\"classification_results.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
